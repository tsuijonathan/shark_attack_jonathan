{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8137c82c-8ffe-4329-8663-597aeb6ce13e",
   "metadata": {},
   "source": [
    "# Imports\n",
    "- All library imports\n",
    "- Original DataFrame import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0546618e-4156-431b-9b36-c503bf98a0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "shark_df = pd.read_excel('../shark-dataset.xls')\n",
    "# shark_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f89f81-825c-4838-a2b6-756f9d887877",
   "metadata": {},
   "source": [
    "### Column cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1979d068-e657-4105-b3a9-057f58c5baae",
   "metadata": {},
   "outputs": [],
   "source": [
    "unused_columns = ['type', 'state', 'name', 'location', 'species', 'source', 'pdf', 'href_formula', 'href', 'case_number', 'case_number.1', 'original_order', 'unnamed:_21', 'unnamed:_22', 'time', 'injury']\n",
    "\n",
    "def clean_columns(df):\n",
    "    df.columns = df.columns.str.lower().str.strip().str.replace(\" \", \"_\", regex=False) # lowercase col names, remove+replace empty spaces\n",
    "    df.rename(columns={'unnamed:_11': 'fatal'}, inplace=True)\n",
    "    df = df.drop(unused_columns, axis=1, errors='ignore')\n",
    "    return df\n",
    "\n",
    "shark_df = clean_columns(shark_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0238a40-20a4-44cb-a314-57759e836b63",
   "metadata": {},
   "source": [
    "### Year filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93d74206-2687-4aec-bbf5-a97abf38541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = 2014\n",
    "end_year = 2024\n",
    "\n",
    "shark_df = shark_df[(shark_df[\"year\"] >= start_year) & (shark_df[\"year\"] <= end_year)]\n",
    "\n",
    "#convert float in year to int\n",
    "shark_df[\"year\"] = shark_df[\"year\"].fillna(0).astype(int)\n",
    "\n",
    "# remove invalid rows with \"2014\" as date\n",
    "shark_df = shark_df.drop(shark_df.index[-2:])\n",
    "\n",
    "\n",
    "total_count_spring = 298\n",
    "total_count_summer = 405\n",
    "total_count_autumn = 290\n",
    "total_count_winter = 231\n",
    "\n",
    "# shark_df\n",
    "# shark_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8211cf-f251-4a75-b381-4d56064487b7",
   "metadata": {},
   "source": [
    "### Date & Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f44c871-9396-480b-90ae-f29879a92bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse different date formats\n",
    "def parse_date(date_str):\n",
    "    if isinstance(date_str, str):\n",
    "        try: \n",
    "            return pd.to_datetime(date_str)  # Try direct conversion\n",
    "        except ValueError:\n",
    "            match = re.search(r'(\\d{4}-\\d{1,2}-\\d{1,2}|\\d{1,2}-[A-Za-z]{3}-\\d{4}|\\b[A-Za-z]{3}-\\d{4}\\b)', date_str)\n",
    "            if match:\n",
    "                date_str = match.group(0)\n",
    "                try:\n",
    "                    return datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "                except ValueError:\n",
    "                    try:\n",
    "                        return datetime.strptime(date_str, \"%d-%b-%Y\")\n",
    "                    except ValueError:\n",
    "                        try:\n",
    "                            return datetime.strptime(date_str, \"%b-%Y\")\n",
    "                        except ValueError:\n",
    "                            return None  # Return None for invalid formats\n",
    "    elif isinstance(date_str, datetime):\n",
    "        return date_str  # Return the datetime object as is\n",
    "    return None  # Return None if not a string or datetime\n",
    "\n",
    "# Create datetime_column and string_column\n",
    "shark_df[\"datetime_column\"] = shark_df[\"date\"].apply(parse_date)\n",
    "shark_df[\"string_column\"] = shark_df[\"date\"].apply(lambda x: x if isinstance(x, str) else None)\n",
    "\n",
    "# Drop rows with invalid datetime values\n",
    "shark_df = shark_df[shark_df[\"datetime_column\"].notna()]\n",
    "\n",
    "# Extract month and year from datetime_column\n",
    "shark_df['month'] = shark_df[\"datetime_column\"].apply(lambda x: x.month if pd.notnull(x) else None)\n",
    "shark_df['year'] = shark_df[\"datetime_column\"].apply(lambda x: x.year if pd.notnull(x) else None)\n",
    "\n",
    "# Define season mapping\n",
    "season_mapping = {\n",
    "    \"Spring\": [3, 4, 5],\n",
    "    \"Summer\": [6, 7, 8],\n",
    "    \"Autumn\": [9, 10, 11],\n",
    "    \"Winter\": [12, 1, 2]\n",
    "}\n",
    "\n",
    "# Function to assign season based on month\n",
    "def what_season(month):\n",
    "    for season, months in season_mapping.items():\n",
    "        if month in months:\n",
    "            return season\n",
    "    return None\n",
    "\n",
    "# Assign season based on the extracted month\n",
    "shark_df['season'] = shark_df['month'].apply(what_season)\n",
    "\n",
    "# shark_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233f5498-7864-46ea-8a98-1c9ab2f79919",
   "metadata": {},
   "source": [
    "### Fatality rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "864a025d-2fec-48f1-8326-6c8558d6aa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fatality_data(df):\n",
    "    df.rename(columns={'unnamed:_11': 'fatal'}, inplace=True)\n",
    "    replacement_dict = {\n",
    "        'N': 'no',\n",
    "        'Y': 'yes',\n",
    "        'M': 'unknown',\n",
    "        'F': 'unknown',\n",
    "        'n': 'no',\n",
    "        'Nq': 'unknown'\n",
    "    }\n",
    "    df['fatal'] = df['fatal'].fillna('unknown').replace(replacement_dict) #fill NaN vals with 'unknown' and replace unique values\n",
    "    return df\n",
    "\n",
    "shark_df = process_fatality_data(shark_df)\n",
    "\n",
    "# shark_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a9a8c2-5c9c-495b-b3f8-fbfd1d0922eb",
   "metadata": {},
   "source": [
    "### Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6cb0912-0963-4520-b918-f9617d72b419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# values to a common case\n",
    "shark_df['activity'] = shark_df['activity'].str.strip().str.lower().str.replace(r\"[\\\"']\", '', regex=True)\n",
    "\n",
    "most_common_words = []\n",
    "\n",
    "def word_count():\n",
    "    global most_common_words  # declare the global variable\n",
    "    shark_df['activity'] = shark_df['activity'].fillna('').astype(str)  # replace NaN values with an empty string\n",
    "    all_text = ' '.join(shark_df['activity'])  # combine all values into a single string\n",
    "    words = re.findall(r'\\w+', all_text.lower())  # split into words\n",
    "    word_counts = Counter(words)  # count word frequency\n",
    "    most_common_words = [word for word, count in word_counts.most_common(50) if len(word) >= 5]\n",
    "    return most_common_words\n",
    "\n",
    "most_common_words = word_count()\n",
    "\n",
    "selected_values_to_replace = ['surfing', 'diving', 'fishing', 'swimming', 'wading', 'bathing', 'snorkeling', 'kayaking', 'body boarding', 'scuba diving']\n",
    "\n",
    "def replace_values(shark_df, selected_values_to_replace):\n",
    "    for word_to_replace in selected_values_to_replace:\n",
    "        shark_df.loc[shark_df['activity'].str.contains(word_to_replace, case=False, na=False), 'activity'] = word_to_replace\n",
    "    return shark_df\n",
    "\n",
    "shark_df = replace_values(shark_df, selected_values_to_replace)\n",
    "\n",
    "# remove empty values\n",
    "shark_df = shark_df[shark_df['activity'].apply(lambda x: x.strip() != '')]\n",
    "\n",
    "# retrieve 10 top activities within filtering step\n",
    "shark_df = shark_df[shark_df['activity'].isin((lambda x: x.index)(shark_df['activity'].value_counts().head(10)))] \n",
    "\n",
    "# print(shark_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafe1fa1-7dfe-43ff-8f56-baf457d48d4c",
   "metadata": {},
   "source": [
    "### Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c98118b9-b7e6-4698-82eb-f7e05dfaea89",
   "metadata": {},
   "outputs": [],
   "source": [
    "shark_df['sex'] = shark_df['sex'].str.strip()\n",
    "\n",
    "# Replace specific values\n",
    "shark_df['sex'] = shark_df['sex'].replace({\n",
    "    'M': 'M', \n",
    "    'F': 'F',  \n",
    "    'N': np.nan,  \n",
    "    'M x 2': 'M', \n",
    "    'lli': np.nan,  \n",
    "    '.': np.nan,  \n",
    "    ' M': 'M'  \n",
    "})\n",
    "\n",
    "shark_df['sex']= shark_df['sex'].fillna('unknown')\n",
    "\n",
    "#Calculate the counts of \"M\" and \"F\"\n",
    "total_known = shark_df['sex'].value_counts()\n",
    "m_count = total_known.get('M', 0)\n",
    "f_count = total_known.get('F', 0)\n",
    "total = m_count + f_count\n",
    "\n",
    "#Calculate the percentages of \"M\" and \"F\"\n",
    "if total > 0:\n",
    "    m_percentage = m_count / total\n",
    "    f_percentage = f_count / total\n",
    "else:\n",
    "    m_percentage = 0.5  # Default to equal distribution if no known values\n",
    "    f_percentage = 0.5\n",
    "\n",
    "# Determine the number of \"Unknown\" values\n",
    "unknown_count = shark_df['sex'].value_counts().get('unknown', 0)\n",
    "\n",
    "# Calculate how many \"Unknown\" values to fill with \"M\" and \"F\"\n",
    "m_fill_count = int(m_percentage * unknown_count)\n",
    "f_fill_count = unknown_count - m_fill_count  # Ensure all \"Unknown\" are assigned\n",
    "\n",
    "# Get indices of the \"Unknown\" entries\n",
    "unknown_indices = shark_df[shark_df['sex'] == 'unknown'].index\n",
    "\n",
    "# Randomly shuffle the \"Unknown\" indices\n",
    "shuffled_indices = np.random.permutation(unknown_indices)\n",
    "\n",
    "# Split the shuffled indices into two groups for \"M\" and \"F\"\n",
    "m_indices = shuffled_indices[:m_fill_count]\n",
    "f_indices = shuffled_indices[m_fill_count:]\n",
    "\n",
    "# Assign \"M\" and \"F\" to the split indices\n",
    "shark_df.loc[m_indices, 'sex'] = 'M'\n",
    "shark_df.loc[f_indices, 'sex'] = 'F'\n",
    "\n",
    "# Verify replacements by checking updated counts\n",
    "# print(shark_df['sex'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de13696-0c6b-4174-b552-18ed7168c957",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa24d600-80f8-4812-9eb8-c38c7463de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_descriptive_age(value):\n",
    "    if pd.isnull(value):\n",
    "        return np.nan\n",
    "    value = str(value).strip().lower()\n",
    "    if value in [\"teen\", \"teens\"]:\n",
    "        return 15  # Approximate age for teenagers\n",
    "    elif value == \"adult\":\n",
    "        return 30  # General average for adult age\n",
    "    elif value in [\"middle age\", '\"middle-age\"']:\n",
    "        return 45  # Approximate age for middle age\n",
    "    elif value == \"elderly\":\n",
    "        return 70  # Approximate age for elderly\n",
    "    elif value in [\"a minor\", \"young\"]:\n",
    "        return 10  # Assume a minor is around 10 years old\n",
    "    elif value == \"infant\" or value == \"9 months\" or value == \"2 to 3 months\":\n",
    "        return 1  # Age 1 for infants\n",
    "    elif \"month\" in value:\n",
    "        return 1  # Treat other month values as infants\n",
    "    return value\n",
    "\n",
    "shark_df['age'] = shark_df['age'].apply(convert_descriptive_age)\n",
    "\n",
    "def convert_to_first_age(value):\n",
    "    if isinstance(value, str):\n",
    "        numbers = re.findall(r'\\d+', value)\n",
    "        if numbers:\n",
    "            return int(numbers[0])  \n",
    "    return value\n",
    "\n",
    "shark_df['age'] = shark_df['age'].apply(convert_to_first_age)\n",
    "\n",
    "def convert_half_age(value):\n",
    "    if isinstance(value, str) and \"½\" in value:\n",
    "        # Replace \"½\" with \".5\" and convert to float\n",
    "        return float(value.replace(\"½\", \".5\"))\n",
    "    return value  \n",
    "\n",
    "shark_df['age'] = shark_df['age'].apply(convert_half_age)\n",
    "\n",
    "\n",
    "#Convert any remaining irregular entries to NaN\n",
    "def convert_irregular_entries(value):\n",
    "    if isinstance(value, str) and not any(char.isdigit() for char in value):\n",
    "        return np.nan  \n",
    "    return value\n",
    "\n",
    "shark_df['age'] = shark_df['age'].apply(convert_irregular_entries)\n",
    "\n",
    "#convert to numeric\n",
    "shark_df['age'] = pd.to_numeric(shark_df['age'], errors='coerce')\n",
    "\n",
    "#Replace NaN values with the mode of the age column\n",
    "age_mode = shark_df['age'].mode()[0]\n",
    "shark_df['age'] = shark_df['age'].fillna(age_mode)\n",
    "\n",
    "#convert type to int\n",
    "shark_df['age'] = shark_df['age'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42675f43-7df3-44f8-acd6-f8d9ccd12901",
   "metadata": {},
   "source": [
    "### Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b065be5d-d91e-433d-b5d6-8e025199b46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# capitalize names except for 'USA', handle two-word countries\n",
    "def country_formatting(df):\n",
    "    df['country'] = df['country'].apply(lambda x: \n",
    "        ' '.join(word.capitalize() for word in x.split()) if isinstance(x, str) and x.lower() != 'usa' else x)\n",
    "    return df\n",
    "\n",
    "shark_df = country_formatting(shark_df)\n",
    "\n",
    "# ilter df based on the top 10 countries\n",
    "shark_df = shark_df[shark_df['country'].isin(shark_df['country'].value_counts().head(10).index)]\n",
    "\n",
    "# print(shark_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30370fad-3276-42b5-b314-33821860dfac",
   "metadata": {},
   "source": [
    "### Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "360841b6-2c0f-4ac1-a0bc-41b63edc0be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year           country activity sex  age fatal  season\n",
      "1     2024               USA  surfing   M   16    no  Autumn\n",
      "6     2024         Australia  surfing   M   23    no  Summer\n",
      "7     2024         Australia  surfing   M   41    no  Summer\n",
      "8     2024               USA   diving   M   14    no  Summer\n",
      "9     2024               USA   wading   M   26    no  Summer\n",
      "...    ...               ...      ...  ..  ...   ...     ...\n",
      "1223  2014  French Polynesia  surfing   M   21    no  Winter\n",
      "1225  2014         Australia   diving   M   28   yes  Winter\n",
      "1227  2014       New Zealand  surfing   M   28    no  Winter\n",
      "1228  2014         Australia  fishing   M   15    no  Winter\n",
      "1229  2014       New Zealand  fishing   M   24    no  Winter\n",
      "\n",
      "[904 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Columns to remove\n",
    "columns_to_remove = ['date', 'datetime_column', 'string_column', 'month']\n",
    "\n",
    "# Remove the specified columns\n",
    "shark_df = shark_df.drop(columns=columns_to_remove)\n",
    "\n",
    "print(shark_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a3076f-5acd-436a-aba9-4d46bef69ab7",
   "metadata": {},
   "source": [
    "## Final: Generate `shark_final_df.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea2c5e7c-11d4-45cd-9142-d8215dd5a4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shark_final_df = shark_df.to_csv('shark_final_df.csv', index=False)\n",
    "shark_final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d22c3d60-ea04-47c2-be5b-fe35cd55bd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we went from 6973 rows x 23 columns to 904 rows x 7 columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
